The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
NYU_v2
SceneNet(
  (backbone): Deeplab_ResNet_Backbone(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)
    (blocks): ModuleList(
      (0): ModuleList(
        (0-2): 3 x BasicBlock(
          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ModuleList(
        (0): BasicBlock(
          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-3): 3 x BasicBlock(
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): ModuleList(
        (0): BasicBlock(
          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-5): 5 x BasicBlock(
          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (3): ModuleList(
        (0): BasicBlock(
          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1-2): 2 x BasicBlock(
          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (ds): ModuleList(
      (0): None
      (1): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (task1_fc1_c0): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task1_fc1_c1): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task1_fc1_c2): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task1_fc1_c3): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task2_fc1_c0): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task2_fc1_c1): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task2_fc1_c2): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (task2_fc1_c3): Classification_Module(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))
    (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
    (conv3): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))
    (relu): ReLU(inplace=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
<class 'list'>
preds: [tensor([[[[ 4.2072e+00,  4.2948e+00,  4.0025e+00,  ...,  4.1135e+00,
            4.0078e+00,  4.0375e+00],
          [ 4.8079e+00,  4.0154e+00,  3.0359e+00,  ...,  4.8428e+00,
            4.6904e+00,  4.4912e+00],
          [ 4.8100e+00,  4.3537e+00,  2.6397e+00,  ...,  4.9384e+00,
            4.8266e+00,  4.7817e+00],
          ...,
          [ 2.9454e+00,  2.4797e+00,  2.9348e+00,  ...,  1.1109e+00,
            1.2082e+00,  2.4731e+00],
          [ 2.5481e+00,  1.9648e+00,  2.5543e+00,  ...,  1.1533e+00,
            9.5572e-01,  2.7170e+00],
          [ 2.0616e+00,  2.0576e+00,  2.1352e+00,  ...,  1.1179e+00,
            1.0877e+00,  2.6292e+00]],

         [[-5.1364e-01, -3.3004e-02, -3.6262e-01,  ..., -1.6139e+00,
           -1.3906e+00, -1.4181e+00],
          [-5.1557e-01, -5.3980e-01, -1.2818e+00,  ..., -2.4182e+00,
           -2.3174e+00, -2.1274e+00],
          [-6.0674e-01, -5.2659e-01, -1.7709e+00,  ..., -2.7247e+00,
           -2.1806e+00, -2.2215e+00],
          ...,
          [-2.5763e-01,  3.0003e-01, -2.1260e-01,  ...,  6.6797e+00,
            5.2982e+00,  2.7267e+00],
          [ 1.7705e-01,  3.1847e-02, -4.6600e-01,  ...,  6.4638e+00,
            4.8049e+00,  2.9889e+00],
          [ 1.5483e-01,  3.1485e-01, -1.6682e-01,  ...,  6.0055e+00,
            5.1060e+00,  2.5856e+00]],

         [[ 1.6637e+00,  1.5556e+00,  1.2634e+00,  ...,  1.9507e+00,
            1.7280e+00,  2.1648e+00],
          [ 1.7984e+00,  1.4144e+00,  1.8575e+00,  ...,  2.5789e+00,
            2.5286e+00,  2.5029e+00],
          [ 1.6594e+00,  1.7831e+00,  1.8177e+00,  ...,  2.7560e+00,
            2.4416e+00,  2.6713e+00],
          ...,
          [ 2.0317e+00,  1.7777e+00,  2.4569e+00,  ...,  1.3383e+00,
            1.2262e+00,  1.6435e+00],
          [ 1.9129e+00,  1.4906e+00,  2.5250e+00,  ...,  1.2275e+00,
            1.1736e+00,  1.8248e+00],
          [ 1.6207e+00,  1.6880e+00,  2.2010e+00,  ...,  1.0371e+00,
            1.1398e+00,  1.8234e+00]],

         ...,

         [[ 8.9138e-01,  8.1294e-01,  1.1576e+00,  ...,  4.1797e+00,
            3.9069e+00,  3.2349e+00],
          [ 1.0855e+00,  1.4209e+00,  1.7193e+00,  ...,  4.8333e+00,
            4.6821e+00,  3.8754e+00],
          [ 1.0773e+00,  1.1445e+00,  1.8200e+00,  ...,  4.8091e+00,
            4.1971e+00,  3.7194e+00],
          ...,
          [ 4.6670e-01,  7.2873e-02,  1.4953e-01,  ..., -6.8225e-01,
           -5.7584e-01, -2.7857e-01],
          [ 2.2230e-01, -1.2480e-01,  3.0228e-01,  ..., -9.2321e-01,
           -7.5762e-01, -5.6061e-01],
          [ 4.0054e-01,  6.8036e-02,  2.6814e-01,  ..., -6.3914e-01,
           -7.6120e-01, -3.3047e-01]],

         [[ 1.7334e-01,  2.8808e-01,  4.9098e-01,  ...,  6.0354e-01,
            6.0027e-01,  5.4985e-01],
          [ 1.1059e-01,  1.4626e-01,  5.2736e-01,  ...,  8.2465e-01,
            8.2815e-01,  6.3478e-01],
          [ 3.7161e-03,  2.0271e-01,  3.9546e-01,  ...,  8.4227e-01,
            8.6421e-01,  6.7549e-01],
          ...,
          [-7.9679e-02,  2.5094e-01,  4.2155e-01,  ...,  2.3722e+00,
            1.6861e+00,  1.6470e+00],
          [-1.4340e-02,  3.2920e-01,  5.3615e-01,  ...,  2.3755e+00,
            1.7762e+00,  1.5279e+00],
          [ 1.9306e-01,  4.5276e-01,  6.1888e-01,  ...,  2.2465e+00,
            1.8420e+00,  1.3966e+00]],

         [[ 2.4211e-01,  2.1449e-01,  4.5040e-01,  ...,  1.8302e+00,
            1.6176e+00,  1.2380e+00],
          [ 2.6082e-02,  7.0530e-01,  1.0765e+00,  ...,  1.9555e+00,
            1.8857e+00,  1.3618e+00],
          [ 2.4652e-01,  5.1511e-01,  1.3650e+00,  ...,  1.9165e+00,
            1.5010e+00,  1.0412e+00],
          ...,
          [ 1.1903e+00,  1.3246e+00,  1.1849e+00,  ...,  1.8614e+00,
            1.5031e+00,  1.1842e+00],
          [ 1.0156e+00,  1.5381e+00,  1.0002e+00,  ...,  1.8799e+00,
            1.6019e+00,  9.7055e-01],
          [ 1.1380e+00,  1.2649e+00,  1.3174e+00,  ...,  1.9555e+00,
            1.6486e+00,  1.0228e+00]]]], device='cuda:0',
       grad_fn=<AddBackward0>), tensor([[[[1.0005, 0.9766, 1.3110,  ..., 0.2887, 0.2810, 0.4696],
          [1.1248, 1.2081, 1.2392,  ..., 0.1852, 0.2340, 0.4557],
          [1.1867, 1.4471, 1.6357,  ..., 0.1280, 0.2424, 0.5435],
          ...,
          [1.0896, 1.2721, 1.6519,  ..., 3.4137, 3.0973, 1.7841],
          [1.1322, 1.2169, 1.4721,  ..., 3.2071, 2.7650, 1.6566],
          [1.1709, 1.0440, 1.3221,  ..., 2.8045, 2.5116, 1.2802]],

         [[0.4637, 0.5263, 0.6001,  ..., 1.0952, 1.0120, 0.8019],
          [0.5270, 0.6811, 1.1477,  ..., 1.4932, 1.3730, 0.8807],
          [0.5741, 0.8975, 1.3780,  ..., 1.5694, 1.1088, 0.7020],
          ...,
          [0.3971, 0.4921, 0.6739,  ..., 1.3231, 1.1904, 0.7628],
          [0.4253, 0.5047, 0.5819,  ..., 1.2168, 1.0533, 0.6687],
          [0.4667, 0.4630, 0.5530,  ..., 1.0638, 0.9586, 0.5725]],

         [[0.9472, 0.8296, 0.9975,  ..., 1.3025, 1.2008, 1.1074],
          [1.0487, 0.9919, 1.4722,  ..., 1.6154, 1.5087, 1.1436],
          [1.1023, 1.3514, 2.0282,  ..., 1.6770, 1.2465, 0.9722],
          ...,
          [0.9246, 1.0039, 1.3010,  ..., 1.7584, 1.6222, 1.1350],
          [0.9335, 0.9901, 1.2121,  ..., 1.6772, 1.4691, 1.0257],
          [0.9436, 0.8955, 1.0794,  ..., 1.4893, 1.3514, 0.9057]]]],
       device='cuda:0', grad_fn=<AddBackward0>)]
seg: tensor([[[[ 4.2072e+00,  4.2948e+00,  4.0025e+00,  ...,  4.1135e+00,
            4.0078e+00,  4.0375e+00],
          [ 4.8079e+00,  4.0154e+00,  3.0359e+00,  ...,  4.8428e+00,
            4.6904e+00,  4.4912e+00],
          [ 4.8100e+00,  4.3537e+00,  2.6397e+00,  ...,  4.9384e+00,
            4.8266e+00,  4.7817e+00],
          ...,
          [ 2.9454e+00,  2.4797e+00,  2.9348e+00,  ...,  1.1109e+00,
            1.2082e+00,  2.4731e+00],
          [ 2.5481e+00,  1.9648e+00,  2.5543e+00,  ...,  1.1533e+00,
            9.5572e-01,  2.7170e+00],
          [ 2.0616e+00,  2.0576e+00,  2.1352e+00,  ...,  1.1179e+00,
            1.0877e+00,  2.6292e+00]],

         [[-5.1364e-01, -3.3004e-02, -3.6262e-01,  ..., -1.6139e+00,
           -1.3906e+00, -1.4181e+00],
          [-5.1557e-01, -5.3980e-01, -1.2818e+00,  ..., -2.4182e+00,
           -2.3174e+00, -2.1274e+00],
          [-6.0674e-01, -5.2659e-01, -1.7709e+00,  ..., -2.7247e+00,
           -2.1806e+00, -2.2215e+00],
          ...,
          [-2.5763e-01,  3.0003e-01, -2.1260e-01,  ...,  6.6797e+00,
            5.2982e+00,  2.7267e+00],
          [ 1.7705e-01,  3.1847e-02, -4.6600e-01,  ...,  6.4638e+00,
            4.8049e+00,  2.9889e+00],
          [ 1.5483e-01,  3.1485e-01, -1.6682e-01,  ...,  6.0055e+00,
            5.1060e+00,  2.5856e+00]],

         [[ 1.6637e+00,  1.5556e+00,  1.2634e+00,  ...,  1.9507e+00,
            1.7280e+00,  2.1648e+00],
          [ 1.7984e+00,  1.4144e+00,  1.8575e+00,  ...,  2.5789e+00,
            2.5286e+00,  2.5029e+00],
          [ 1.6594e+00,  1.7831e+00,  1.8177e+00,  ...,  2.7560e+00,
            2.4416e+00,  2.6713e+00],
          ...,
          [ 2.0317e+00,  1.7777e+00,  2.4569e+00,  ...,  1.3383e+00,
            1.2262e+00,  1.6435e+00],
          [ 1.9129e+00,  1.4906e+00,  2.5250e+00,  ...,  1.2275e+00,
            1.1736e+00,  1.8248e+00],
          [ 1.6207e+00,  1.6880e+00,  2.2010e+00,  ...,  1.0371e+00,
            1.1398e+00,  1.8234e+00]],

         ...,

         [[ 8.9138e-01,  8.1294e-01,  1.1576e+00,  ...,  4.1797e+00,
            3.9069e+00,  3.2349e+00],
          [ 1.0855e+00,  1.4209e+00,  1.7193e+00,  ...,  4.8333e+00,
            4.6821e+00,  3.8754e+00],
          [ 1.0773e+00,  1.1445e+00,  1.8200e+00,  ...,  4.8091e+00,
            4.1971e+00,  3.7194e+00],
          ...,
          [ 4.6670e-01,  7.2873e-02,  1.4953e-01,  ..., -6.8225e-01,
           -5.7584e-01, -2.7857e-01],
          [ 2.2230e-01, -1.2480e-01,  3.0228e-01,  ..., -9.2321e-01,
           -7.5762e-01, -5.6061e-01],
          [ 4.0054e-01,  6.8036e-02,  2.6814e-01,  ..., -6.3914e-01,
           -7.6120e-01, -3.3047e-01]],

         [[ 1.7334e-01,  2.8808e-01,  4.9098e-01,  ...,  6.0354e-01,
            6.0027e-01,  5.4985e-01],
          [ 1.1059e-01,  1.4626e-01,  5.2736e-01,  ...,  8.2465e-01,
            8.2815e-01,  6.3478e-01],
          [ 3.7161e-03,  2.0271e-01,  3.9546e-01,  ...,  8.4227e-01,
            8.6421e-01,  6.7549e-01],
          ...,
          [-7.9679e-02,  2.5094e-01,  4.2155e-01,  ...,  2.3722e+00,
            1.6861e+00,  1.6470e+00],
          [-1.4340e-02,  3.2920e-01,  5.3615e-01,  ...,  2.3755e+00,
            1.7762e+00,  1.5279e+00],
          [ 1.9306e-01,  4.5276e-01,  6.1888e-01,  ...,  2.2465e+00,
            1.8420e+00,  1.3966e+00]],

         [[ 2.4211e-01,  2.1449e-01,  4.5040e-01,  ...,  1.8302e+00,
            1.6176e+00,  1.2380e+00],
          [ 2.6082e-02,  7.0530e-01,  1.0765e+00,  ...,  1.9555e+00,
            1.8857e+00,  1.3618e+00],
          [ 2.4652e-01,  5.1511e-01,  1.3650e+00,  ...,  1.9165e+00,
            1.5010e+00,  1.0412e+00],
          ...,
          [ 1.1903e+00,  1.3246e+00,  1.1849e+00,  ...,  1.8614e+00,
            1.5031e+00,  1.1842e+00],
          [ 1.0156e+00,  1.5381e+00,  1.0002e+00,  ...,  1.8799e+00,
            1.6019e+00,  9.7055e-01],
          [ 1.1380e+00,  1.2649e+00,  1.3174e+00,  ...,  1.9555e+00,
            1.6486e+00,  1.0228e+00]]]], device='cuda:0',
       grad_fn=<AddBackward0>)

###############################################################################
H치br칩k Cluster
Job 8646331 for user s4716671
Finished at: Thu May  2 09:19:45 CEST 2024

Job details:
============

Job ID              : 8646331
Name                : attempt1
User                : s4716671
Partition           : gpushort
Nodes               : v100gpu34
Number of Nodes     : 1
Cores               : 8
Number of Tasks     : 1
State               : RUNNING
Submit              : 2024-05-02T09:18:14
Start               : 2024-05-02T09:18:15
End                 : --
Reserved walltime   : 00:05:00
Used walltime       : 00:01:30
Used CPU time       : --
% User (Computation): --
% System (I/O)      : --
Mem reserved        : 4G
Max Mem (Node/step) : 0.00  (Node unknown, N/A)
Full Max Mem usage  : 0.00  (Until last completed step)
Total Disk Read     : 0.00  (Until last completed step)
Total Disk Write    : 0.00  (Until last completed step)

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
